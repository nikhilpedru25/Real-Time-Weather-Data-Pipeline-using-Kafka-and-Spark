version: "3.9"

services:
  # Zookeeper for Kafka
  zookeeper:
    image: bitnami/zookeeper:latest
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    ports:
      - "2181:2181"

  # Kafka broker
  kafka:
    image: bitnami/kafka:3.6.0
    ports:
      - "9092:9092"
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092
    depends_on:
      - zookeeper

  # PostgreSQL for Airflow
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data

  # Adminer to manage Postgres DB
  adminer:
    image: adminer:latest
    restart: always
    ports:
      - "8080:8080"

  # Airflow
  airflow:
    image: apache/airflow:2.9.1
    restart: always
    depends_on:
      - postgres
    environment:
      - LOAD_EXAMPLES=yes
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__FERNET_KEY=v0PZ4xXyJt1iGZcYl8y8pR6X7tX3N4B1JhS1n3YvZpM=
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
    ports:
      - "8081:8080"
    volumes:
      - ./dags:/opt/airflow/dags

  # Spark
  spark:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=master
    ports:
      - "7077:7077"
      - "8082:8080"
    volumes:
      - ./spark_jobs:/opt/spark_jobs          # your Spark consumer/producer scripts
      - ./jars:/opt/spark_jars                # local JARs to avoid Ivy issues

  # Grafana
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin

volumes:
  pgdata:
